{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3a33da-54e4-43ef-a134-7d93693186c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Lambda, Multiply, Add, LeakyReLU, Dropout, Conv2D, MaxPool2D, GlobalAveragePooling2D, Flatten, Conv2DTranspose, Permute\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ac5173-83fd-411b-9590-e2920ab52cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(tf.keras.layers.Layer):\n",
    "    def __init__(self, channels, downsample = False, kernal_size = 3):\n",
    "        super(block, self).__init__()\n",
    "        self._channels = channels\n",
    "        self._strides = [2, 1] if downsample else [1, 1]\n",
    "        self._down_sample = downsample\n",
    "        kernal_init = tf.keras.initializers.he_normal()\n",
    "        self.conv_1 = Conv2D(self._channels, kernal_size, strides=self._strides[0], padding=\"same\", kernel_initializer= kernal_init)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(self._channels, kernal_size, strides=self._strides[1], padding=\"same\", kernel_initializer= kernal_init)\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.merge = Lambda(lambda x : Add()([x[0], x[1]]), name= 'z')\n",
    "        if self._down_sample:\n",
    "            self.conv_ds = Conv2D(self._channels, (1,1), strides=2, padding=\"same\", kernel_initializer= kernal_init)\n",
    "            self.bn_ds = BatchNormalization()\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        if self._down_sample:\n",
    "            res = self.conv_ds(res)\n",
    "            res = self.bn_ds(res)\n",
    "        x = self.merge([x, res])   #to avoide vanishing gradient and exploding gradient\n",
    "        out = tf.nn.relu(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791212c5-cdfa-46f3-af2b-cec82d7c117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLeaky(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels):\n",
    "        super(ConvLeaky, self).__init__()\n",
    "        kernel_size = 3\n",
    "        kernal_init = tf.keras.initializers.he_normal()\n",
    "        self.conv1 = Conv2D(out_channels, kernel_size, strides = 1, padding = 'same', kernel_initializer= kernal_init)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv2 = Conv2D(out_channels, kernel_size, strides = 1, padding = 'same', kernel_initializer= kernal_init)\n",
    "        self.bn_2 = BatchNormalization()\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520dd3ff-ca9f-40a0-a3e5-c3ecb00004c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels, typ):\n",
    "        super(FNetBlock, self).__init__()\n",
    "        self.convleaky = ConvLeaky(out_channels)\n",
    "        if typ == \"maxpool\":\n",
    "            self.out = Lambda(lambda x: tf.nn.max_pool2d(x, ksize=(2, 2), strides=(2, 2), padding=\"SAME\"))\n",
    "        elif typ == \"bilinear\":\n",
    "            self.out = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "        else:\n",
    "            raise Exception('typ does not match')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.convleaky(inputs)\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476e30f-867b-49e2-8085-5a9c9651e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing FnetBlock\n",
    "# l = FNetBlock(10, \"bilinear\")\n",
    "# a = np.ones((1, 20, 20, 3))\n",
    "# l(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e18251-9fe9-4119-84cf-8fc6c4edfe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SRNet, self).__init__()\n",
    "        kernel_size = 3\n",
    "        kernal_init = tf.keras.initializers.he_normal()\n",
    "        self.conv_in = Conv2D(64, kernel_size, strides = 1, padding = 'same', kernel_initializer= kernal_init)\n",
    "        self.resBlock = tf.keras.Sequential([block(64) for i in range(0, 10)])\n",
    "        self.deconv1 = Conv2DTranspose(64, kernel_size, strides=(2, 2), padding = 'same')\n",
    "        self.deconv2 = Conv2DTranspose(64, kernel_size, strides=(2, 2), padding = 'valid', output_padding = 1)\n",
    "        self.out_conv = Conv2D(3, kernel_size)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv_in(inputs)\n",
    "        x = self.resBlock(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de51db2d-780b-4fef-9bd0-dcdbbf668f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SRNet testing\n",
    "# m = SRNet()\n",
    "# i = np.ones((1, 20, 20, 3))\n",
    "# m(i).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c9aefe-99f2-4081-8b8e-fa45f89ef195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c6a527-9f6a-474a-ab5f-1e6705bb7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FNet, self).__init__()\n",
    "        #input dim = 6\n",
    "        kernel_size = 3\n",
    "        kernal_init = tf.keras.initializers.he_normal()\n",
    "        self.convpool_1 = FNetBlock(32, \"maxpool\")\n",
    "        self.convpool_2 = FNetBlock(64, \"maxpool\")\n",
    "        self.convpool_3 = FNetBlock(128, \"maxpool\")\n",
    "        self.convbin_1 = FNetBlock(256, \"bilinear\")\n",
    "        self.convbin_2 = FNetBlock(128, \"bilinear\")\n",
    "        self.convbin_3 = FNetBlock(64, \"bilinear\")\n",
    "        self.conv1 = Conv2D(32, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer= kernal_init)\n",
    "        self.conv2 = Conv2D(2, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer= kernal_init)\n",
    "    def call(self, inputs):\n",
    "        x = self.convpool_1(inputs)\n",
    "        x = self.convpool_2(x)\n",
    "        x = self.convpool_3(x)\n",
    "        x = self.convbin_1(x)\n",
    "        x = self.convbin_2(x)\n",
    "        x = self.convbin_3(x)\n",
    "        x = self.conv1(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.nn.tanh(x)\n",
    "        self.x = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45adfc49-1c7a-4e46-b967-401a7a190be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FNet test\n",
    "# f = FNet()\n",
    "# x = np.ones((1, 4000, 40, 6))\n",
    "# x = f(x)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aaeb378-a5ae-4ea3-ac01-ac5a0b2eee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceToDepth(tf.keras.Model):\n",
    "    def __init__(self, block_size):\n",
    "        super(SpaceToDepth, self).__init__()\n",
    "        self.block_size = block_size\n",
    "        self.block_size_sq = block_size*block_size\n",
    "        self.permute = Permute((2, 3, 1))\n",
    "        self.p0 = Permute((2,1,3))\n",
    "        self.p1 = Permute((3,1,2))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = self.permute(inputs)\n",
    "        (batch_size, s_height, s_width, s_depth) = out.shape\n",
    "        d_depth = s_depth*self.block_size_sq\n",
    "        d_width = int(s_width/self.block_size)\n",
    "        d_height = int(s_height/self.block_size)\n",
    "        t_1 = tf.split(out, int(s_width/self.block_size), 2)\n",
    "        stack = [tf.reshape(t_t,(batch_size, d_height, d_depth)) for t_t in t_1]\n",
    "        out = tf.stack(stack, 1)\n",
    "        out = self.p0(out)\n",
    "        out = self.p1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619d4414-ac4c-49c6-a93b-09da42c7a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test SpaceToDepth\n",
    "# a = np.ones((1, 6, 10, 10))\n",
    "# s = SpaceToDepth(2)\n",
    "# s(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1feedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_value(img, x, y):\n",
    "    \"\"\"\n",
    "    Utility function to get pixel value for coordinate\n",
    "    vectors x and y from a  4D tensor image.\n",
    "    Input\n",
    "    -----\n",
    "    - img: tensor of shape (B, H, W, C)\n",
    "    - x: flattened tensor of shape (B*H*W,)\n",
    "    - y: flattened tensor of shape (B*H*W,)\n",
    "    Returns\n",
    "    -------\n",
    "    - output: tensor of shape (B, H, W, C)\n",
    "    \"\"\"\n",
    "    shape = tf.shape(x)\n",
    "    batch_size = shape[0]\n",
    "    height = shape[1]\n",
    "    width = shape[2]\n",
    "\n",
    "    batch_idx = tf.range(0, batch_size)\n",
    "    batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = tf.tile(batch_idx, (1, height, width))\n",
    "\n",
    "    indices = tf.stack([b, y, x], 3)\n",
    "\n",
    "    return tf.gather_nd(img, indices)\n",
    "\n",
    "    \n",
    "def bilinear_sampler(img, coords):\n",
    "\n",
    "    H = tf.shape(img)[1]\n",
    "    W = tf.shape(img)[2]\n",
    "    max_y = tf.cast(H - 1, 'int32')\n",
    "    max_x = tf.cast(W - 1, 'int32')\n",
    "    \n",
    "    # ----------------- Changes below -------------------------\n",
    "    # -> padding_mode = 'border'\n",
    "    # \"#o\" means original,  \"#t\" means modified\n",
    "    # zero = tf.zeros([], dtype='int32')     #o\n",
    "    zero = tf.zeros([1], dtype=tf.int32)     #t\n",
    "    eps = tf.constant([0.5], 'float32')      #t\n",
    "\n",
    "    # rescale x and y to [0, W-1/H-1]\n",
    "    x, y = coords[:, ..., 0], coords[:, ..., 1]\n",
    "    x = tf.cast(x, 'float32')\n",
    "    y = tf.cast(y, 'float32')\n",
    "\n",
    "    x = 0.5 * ((x + 1.0) * tf.cast(max_x - 1, 'float32'))\n",
    "    y = 0.5 * ((y + 1.0) * tf.cast(max_y - 1, 'float32'))\n",
    "    x = tf.clip_by_value(x, eps, tf.cast(max_x, tf.float32) - eps)   #t\n",
    "    y = tf.clip_by_value(y, eps, tf.cast(max_y, tf.float32) - eps)   #t\n",
    "    # -------------- Changes above --------------------\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = tf.cast(tf.floor(x), 'int32')\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.cast(tf.floor(y), 'int32')\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "    x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "    x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "    y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "    y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = tf.cast(x0, 'float32')\n",
    "    x1 = tf.cast(x1, 'float32')\n",
    "    y0 = tf.cast(y0, 'float32')\n",
    "    y1 = tf.cast(y1, 'float32')\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = tf.expand_dims(wa, axis=3)\n",
    "    wb = tf.expand_dims(wb, axis=3)\n",
    "    wc = tf.expand_dims(wc, axis=3)\n",
    "    wd = tf.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97fc5e9-b840-4093-8711-c0cfe6a8ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSVSR(tf.keras.Model):\n",
    "    def __init__(self, batch_size, lr_height, lr_width):\n",
    "        super(FSVSR, self).__init__()\n",
    "        self.SRFactor = 4\n",
    "        self.batch_size = batch_size\n",
    "        self.height = lr_height\n",
    "        self.width = lr_width\n",
    "        self.fnet = FNet()\n",
    "        self.todepth = SpaceToDepth(self.SRFactor)\n",
    "        self.srnet = SRNet()   #self.SRFactor*self.SRFactor*3 + 3\n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        self.lastLrImage = tf.zeros((self.batch_size, self.height, self.width, 3))\n",
    "        self.EstHrImage = tf.zeros((self.batch_size, self.height*self.SRFactor, self.width*self.SRFactor, 3))\n",
    "        width_gap = 2/(self.width)\n",
    "        height_gap = 2/(self.height)\n",
    "        height, width = tf.meshgrid(tf.range(-1, 1 , width_gap), tf.range(-1, 1, height_gap))\n",
    "        self.lr_identity = tf.stack([width, height])\n",
    "        self.lr_identity = tf.transpose(self.lr_identity, [1, 2, 0])\n",
    "\n",
    "        height_gap = 2/(self.height*self.SRFactor)\n",
    "        width_gap = 2/(self.width*self.SRFactor)\n",
    "        height, width = tf.meshgrid(tf.range(-1, 1 , width_gap), tf.range(-1, 1, height_gap))\n",
    "        self.hr_identity = tf.stack([width, height])\n",
    "        \n",
    "    \n",
    "    def call(self, input):\n",
    "        x0x1 = tf.concat([input, self.lastLrImage], axis = 3)\n",
    "\n",
    "        #debug\n",
    "        # print(x0x1.shape)\n",
    "\n",
    "        flow = self.fnet(x0x1)\n",
    "        print(flow.shape)\n",
    "        print(self.lr_identity.shape)\n",
    "        relative_place = flow + self.lr_identity\n",
    "        # relative_place = tf.transpose(relative_place, [0, 2, 3, 1])\n",
    "        # print(relative_place.shape, 'p')\n",
    "        # print(self.lastLrImage.shape)\n",
    "        self.EstLrImg = bilinear_sampler(self.lastLrImage, relative_place)\n",
    "        # print(self.EstLrImg.shape)\n",
    "        relative_placeNCHW = tf.keras.layers.Resizing(self.height*self.SRFactor, self.width*self.SRFactor, interpolation=\"bilinear\")(relative_place)\n",
    "        # print(relative_placeNCHW.shape)\n",
    "        # relative_placeNCHW = tf.transpose(relative_placeNCHW, [0, 2, 3, 1])\n",
    "        afterWrap = bilinear_sampler(self.EstHrImage, relative_placeNCHW)\n",
    "        afterWrap = tf.transpose(afterWrap, [0, 3, 1, 2])\n",
    "        # print(afterWrap.shape)\n",
    "        depthImage = self.todepth(afterWrap)\n",
    "        depthImage = tf.transpose(depthImage, [0, 3, 2, 1])\n",
    "        print(depthImage.shape, 'depth')\n",
    "        print(self.EstLrImg.shape, 'lr')\n",
    "        srInput = tf.concat([depthImage, input], axis = 3)\n",
    "        estImg = self.srnet(srInput)\n",
    "        self.lastLrImage = input\n",
    "        self.EstHrImage = estImg\n",
    "        return self.EstHrImage, self.EstLrImg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02a9acc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 280, 280, 2)\n",
      "(280, 280, 2)\n",
      "(1, 280, 280, 48) depth\n",
      "(1, 280, 280, 3) lr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1120, 1120, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h =280\n",
    "f = FSVSR(1, h, h)\n",
    "a = np.ones((1, h, h, 3))\n",
    "f.init_hidden() \n",
    "f(a)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77058319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, tv_loss_wt ,name='tv_loss'):\n",
    "        super(TVLoss, self).__init__(name=name)\n",
    "        self.tv_loss_wt = tv_loss_wt\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h_x = x.shape[2]\n",
    "        w_x = x.shape[3]\n",
    "        # count_h = x[:,:,1:,:]\n",
    "        count_h = (x.shape[2] - 1)*x.shape[3]*x.shape[1]*x.shape[0]\n",
    "        count_w = (x.shape[3] - 1)*x.shape[2]*x.shape[1]*x.shape[0]\n",
    "\n",
    "        h_tv = tf.reduce_sum(tf.math.square(x[:,:,1:,:]-x[:,:,:h_x-1,:]))\n",
    "        w_tv = tf.reduce_sum(tf.math.square(x[:,:,:,1:]-x[:,:,:,:w_x-1]))\n",
    "        return self.tv_loss_wt*2*(h_tv/count_h+w_tv/count_w)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da1cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51ed1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2a81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cf801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6df06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d5f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc93f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf94b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7fb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a507be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42447207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69c313cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|████████████████████████████████████████| 528M/528M [00:55<00:00, 9.95MB/s]\n"
     ]
    }
   ],
   "source": [
    "vgg = vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e71df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
